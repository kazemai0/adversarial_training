seml:
  name: eval_ind
  executable: experiments/experiment_attack.py
  project_root_dir: ../..
  output_dir: log/

slurm:
  experiments_per_job: 1
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 16G          # memory
    cpus-per-task: 4  # num cores
    time: 0-00:30     # max time, D-HH:MM

fixed:
  data_dir: data/
  artifact_dir: cache
  pert_adj_storage_type: pretrained_ind_adv_final_adj
  pert_attr_storage_type: pretrained_ind_adv_final_attr
  model_storage_type: pretrained_ind_adv_final
  device: 0
  data_device: 0
  make_undirected: True
  idx_to_attack: test
  split_type: inductive
  balance_test: True
  n_per_class: 20
  model_params_add:
    attack: LRBCD



grid:
  model_params_add:
    self_training:
      type: choice
      options: 
        - False
        - True
    exact_norm:
      type: choice
      options:
      - False
      # - True
    robust_epsilon:
        type: choice
        options:
          - 0
          - 0.05
          - 0.1
          - 0.2
  dataset:
    type: choice
    options:
      - cora
      - cora_ml
      - pubmed
      - citeseer
  seed:
    type: choice
    options:
      - 0
      - 1
      - 5
  epsilons: 
    type: choice
    options:
      - [0, 0.01, 0.05, 0.1, 0.25, 0.5, 1]
  model_label:
    type: choice
    options:
     - ChebNetII


LRBCD:
  fixed:
    binary_attr: False
    attack: LRBCD
    attack_params:
      epochs: 400
      fine_tune_epochs: 0
      with_early_stopping: False
      keep_heuristic: WeightOnly
      search_space_size: 500_000
      do_synchronize: True
      lr_factor: 100
      loss_type: tanhMargin
  grid:
    attack_params:
      local_factor:
        type: choice
        options:
          - 0.5
      projection_type:
        type: choice
        options:
          - Greedy
      
